# -*- coding: utf-8 -*-
"""RLSC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iEpfmkGDHOdn5iWZSXSMAUVuNbnY4l5b
"""

!pip install -Iv ray==1.0.0
!pip install or-gym
!pip install numpy==1.19.5
#!pip uinstall lz4

import or_gym
from or_gym.utils import create_env
import ray
from ray.rllib import agents
from ray import tune
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import gridspec

'''
self.periods = 30
        self.I0 = [100, 100, 200]
        self.p = 2
        self.r = [1.5, 1.0, 0.75, 0.5]
        self.k = [0.10, 0.075, 0.05, 0.025]
        self.h = [0.15, 0.10, 0.05]
        self.c = [100, 90, 80]
        self.L = [3, 5, 10]
        self.backlog = True
        self.dist = 1
        self.dist_param = {'mu': 10}
        self.alpha = 0.97
        self.seed_int = 0
        self.user_D = np.zeros(self.periods)
        self._max_rewards = 2000
'''

# Environment and RL Configuration Settings
env_name = 'InvManagement-v1'
env_config = {'I0': [50, 50, 50, 50],
              'p': 3,
              'dist': 1,
              'dist_param': {'mu': 20},
              'alpha':0.97,
              'seed_int': 0,
              'max_rewards': 5000,
              'r': [1.5, 1.0, 0.75, 0.5, 0.5],
              'k': [0.10, 0.075, 0.05, 0.025, 0.025],
              'h': [0.15, 0.10, 0.05, 0.05],
              'c':[100, 100, 100, 100],
              'L': [2, 3, 3, 5],
              'periods': 30} # Change environment parameters here

env = or_gym.make('InvManagement-v1', env_config=env_config)


def register_env(env_name, env_config=env_config):
    env = create_env(env_name)
    tune.register_env(env_name,
        lambda env_name: env(env_name,
            env_config=env_config))

rl_config = dict(
    env=env_name,
    num_workers=2,
    env_config=env_config,
    model=dict(
        vf_share_layers=False,
        fcnet_activation='elu',
        fcnet_hiddens=[256, 256]
    ),
    lr=1e-5,
    train_batch_size=2000

)
# Register environment
register_env(env_name, env_config)

# Initialize Ray and Build Agent
ray.init(ignore_reinit_error=True)
agent = agents.ppo.PPOTrainer(env=env_name, config=rl_config)
results = []
for i in range(500):
    res = agent.train()
    results.append(res)
    '''
    try:
      res = agent.train()
      results.append(res)
    except ValueError:
      results.append(results[-1])'''

    '''
    if (i+1) % 5 == 0:
        print('\rIter: {}\tReward: {:.2f}'.format(
                i+1, res['episode_reward_mean']), end='')'''
    print('\rIter: {}\tReward: {:.2f}'.format(i + 1, res['episode_reward_mean']), end='')

rewards = np.hstack([i['hist_stats']['episode_reward']
    for i in results])

p = 100
mean_rewards = np.array([np.mean(rewards[i-p:i+1])
                if i >= p else np.mean(rewards[:i+1])
                for i, _ in enumerate(rewards)])
std_rewards = np.array([np.std(rewards[i-p:i+1])
               if i >= p else np.std(rewards[:i+1])
               for i, _ in enumerate(rewards)])
fig = plt.figure(constrained_layout=True, figsize=(15, 5))
gs = fig.add_gridspec(2, 4)
ax0 = fig.add_subplot(gs[:, :-2])
ax0.fill_between(np.arange(len(mean_rewards)),
                 mean_rewards - std_rewards,
                 mean_rewards + std_rewards,
                 label='Standard Deviation', alpha=0.3)
ax0.plot(mean_rewards, label='Mean Rewards')
ax0.set_ylabel('Rewards ($)')
ax0.set_xlabel('Training episode')
ax0.set_title('Training Rewards')
ax0.legend()
plt.grid()
plt.show()

episode_reward = 0
done = False
obs = env.reset()
observations = []
while not done:
  action = agent.compute_action(obs)
  obs, reward, done, info = env.step(action)
  episode_reward += reward
  observations.append(obs)
ray.shutdown()

inv1 = []
inv2 = []
inv3 = []
inv4 = []
days = []
for i in range(len(observations)):
  inv1.append(observations[i][0])
  inv2.append(observations[i][1])
  inv3.append(observations[i][2])
  inv4.append(observations[i][3])
  days.append(i)
#fig = plt.figure(constrained_layout=True, figsize=(30, 10))
plt.plot(days, inv1, color='green', label='retail')
plt.plot(days, inv2, '--', color='black', label='wholesale')
plt.plot(days, inv3, '-.', color='red', label='production (semi-finished)')
plt.plot(days, inv4, ':', color='blue', label='production (finished)')
plt.grid()
plt.legend()
plt.xlabel('days')
plt.ylabel('inventory level')
plt.show()